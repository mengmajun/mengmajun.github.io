# 资料

- https://github.com/Whu-BrainLab/Embodied-AI-Tutorial  动手做具身智能：从算法到实机部署的“通关”实践指南

# 实践动手

## 大模型

### 手写transformer

### 手写gpt2

## RL

### 强化学习基础

### PPO 四足

### PPO 人形

## VLA 动作大模型 复现+手写

### act

### difussion policy

### openVLA

### pi0、pi0.5

# 论文阅读准备

## VLA 动作大模型

### act

### difussion policy

### openVLA

### pi0、pi0.5

## VLN 导航大模型

### QUAR-VLA **

开源信息：2026.01.04 暂时没有开源数据集和模型，有仿真环境的演示

由西湖大学和浙江大学的研究团队开发，并已被 ECCV 2024 接收。

一句话总结：使用自然语言控制四足机器人进行导航，可以在仿真环境中导航，也可以在真实环境中

数据集：作者自己收集了一个数据集，isaacsim中的仿真数据和真实环境操作机器人的数据，数据就是图像+语言导航指令+机器人的动作

模型架构：openVLA模型架构，基础模型Fuyu-8B，系统频率2hz

改进方向：使用pi架构，提高系统频率

### InternVLA-N1 ****

模型架构：双系统，60hz
