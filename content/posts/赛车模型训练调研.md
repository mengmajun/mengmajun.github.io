+++ 
date = '2025-10-11' 
draft = false 
title = '赛车模型训练调研' 
categories = ['强化学习', '赛车'] 
+++

## 训练目标

训练一个能够在**真实赛车环境中运行的视觉语言动作（VLA）模型**，以教学为目的，最终实现从仿真到真实世界的迁移。

---

## 模拟环境

以下是一些适合用于赛车训练的轻量级或高保真模拟器，支持与真实小车平台对接：

### 🏁 TORCS (The Open Racing Car Simulator)
- 开源 3D 赛车模拟器，历史悠久。
- 支持 AI 控制接口，可集成 Python 进行强化学习实验。
- 虽然画面较老，但资源占用低，适合算法原型开发。

### 🚗 CARLA
- 基于 Unreal Engine 的高保真实驾驶仿真平台。
- 主要面向自动驾驶研究，支持复杂城市道路、传感器模拟（摄像头、LiDAR 等）。
- 可用于端到端驾驶策略训练，但对硬件要求较高。

🔗 官网: https://carla.org/

### 🏎️ f1tenth_gym
- 面向 **F1TENTH 赛车竞赛** 的仿真环境，社区活跃。
- 基于 Gazebo + ROS 构建，物理真实性强，支持激光雷达和动力学建模，不支持图像
- 支持 Sim-to-Real（仿真到现实）迁移，非常适合教学和科研项目。

📚 学习资源: https://roboracer.ai/learn  
📦 GitHub: https://github.com/f1tenth/f1tenth_gym 
https://github.com/NicolasHHH/Catkin_ws_F110

赛道：https://github.com/f1tenth/f1tenth_racetracks

### 🛠️ Donkey Car Simulators
- 基于 **Unity 游戏引擎** 构建，提供逼真的视觉渲染和物理系统。
- 是 [Donkey Car](https://donkeycar.com) 开源遥控车项目的配套模拟器，支持数据采集、训练与测试闭环。
- 使用 `gym-donkeycar` 包装为 OpenAI Gym 接口，易于集成 RL 框架。
- 支持自定义赛道、多相机视角、手动驾驶记录等。

🎮 官方文档（中文）: https://donkeycar.cn/guide/deep_learning/simulator/  
🔧 GitHub: https://github.com/tawnkramer/gym-donkeycar 模拟器

https://zhuanlan.zhihu.com/p/44521096

https://github.com/autorope/donkeycar

https://github.com/ian0/donkeycar-rl  不同的强化学习算法训练

https://flyyufelix.github.io/2018/09/11/donkey-rl-simulation.html 通过模拟器强化学习训练的实践教程

### Racecar Gym

https://github.com/axelbr/racecar_gym

F1类似的赛车环境，支持gym

### AirSim

非常真实，虚幻引擎

### l2r

真实，支持gym，相机

https://github.com/learn-to-race/l2r

https://learn-to-race.readthedocs.io/en/latest/

---

## 技术方案

### 🧠 小规模视觉语言模型（Small-scale VLM）

#### smolVLM-500M
- 轻量级视觉语言模型主干，参数量约 5 亿。
- 适用于边缘设备部署，训练成本低。
- 可作为 VLA 模型的图像编码器和语言理解模块。


#### OpenGVLab/InternVL2-1B 
- InternViT-300M-448px	Qwen2-0.5B-Instruct


#### Unsolth的qwenVL

---

### 🤖 机器人操作 VLA 模型

#### smolVLA
- 基于 **smolVLM** 构建的小规模视觉语言动作（VLA）模型。
- 专为机械臂等机器人任务设计，输入为图像+指令，输出为动作序列。
- 使用 **流匹配（Flow Matching）** 方法进行训练，生成连续的动作轨迹。

##### 相关方法：
- **pi0 / pi0.5**：基于离线数据的无监督动作先验学习方法，在生成动作时也采用流匹配方式。
- 输出长度：通常生成 **50 个时间步**的动作指令序列。

---

### 🚘 自动驾驶 VLA 模型

#### SimLingo
- 针对 CARLA 等自动驾驶仿真环境设计的 VLA 框架。
- 视觉主干：**InternVL2-1B**
- 语言主干：**Qwen2-0.5B**
- 功能：根据自然语言指令和视觉输入预测航点（waypoints），实现语义化导航。
- https://arxiv.org/abs/2503.09594

#### autoVLA
- 专为自动驾驶任务设计的视觉语言动作模型。
- 视觉语言主干：**Qwen2.5-VL-3B**
- 输入：摄像头图像 + 自然语言指令（如“靠右行驶”、“避开障碍物”）
- 输出：控制信号（转向、油门、刹车）或未来轨迹点。
- 监督微调+强化学习GRPO微调，快慢思考模型，可以输出思维链
- 暂时没有代码

---

### 🎮 经典强化学习方法

#### PPO（Proximal Policy Optimization）
- 使用 **PPO 算法**训练赛车控制器。
- 输入可以是图像（像素）或状态向量（速度、位置、CTE等）。
- 输出为连续动作空间 `[steering, throttle, brake]`。
- 可在 `f1tenth_gym` 或 `CarRacing-v2` 环境中快速验证。

✅ 优势：
- 稳定、易调试、适合教学；
- 可结合 CNN 处理图像输入；
- 易于迁移到真实 Donkey Car 或 F1TENTH 小车平台。

---

## 总结：推荐技术路线（教学 + 迁移）

| 阶段 | 推荐方案 |
|------|----------|
| **仿真环境** | `f1tenth_gym` 或 `Donkey Car Simulator`（平衡真实性与性能） |
| **视觉主干** | `smolVLM-500M` 或 `InternVL2-1B`（根据算力选择） |
| **语言主干** | `Qwen2-0.5B` |
| **VLA 架构** | `smolVLA` / `SimLingo` 风格，使用 Flow Matching 训练 |
| **控制策略** | 输出 50 步动作序列，或直接回归控制量 |
| **备选方案** | 若 VLA 复杂度高，可用 **PPO** 作为基线方法先行训练 |

> 💡 **最终目标**：在仿真中训练完成后，将模型部署到真实 Donkey Car 或 F1TENTH 实体车上，完成 Sim-to-Real 迁移验证。


## 计划

- 实际部署模拟环境，查看效果怎么样，优先donkey car
- 训练PPO模型：最好挑选一个已经训练好的模型，能够直接用
- 训练smolVLA：smolVLA用于机器人控制，直接输出的控制指令，那么理论上也是可以控制赛车的
  - 收集数据集 lerobot的格式
